{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e450d8c9-108e-4863-8fc2-ac97b288cf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado correctamente.\n",
      "Preparación de datos completada.\n",
      "\n",
      "Dataset dividido en:\n",
      "  - Conjunto de Entrenamiento: 455 muestras\n",
      "  - Conjunto de Prueba: 114 muestras\n",
      "\n",
      "Iniciando validación cruzada sobre el conjunto de entrenamiento...\n",
      "\n",
      "Evaluando modelo: Árbol de Decisión\n",
      "  k=5: Precisión Promedio (CV en entrenamiento) = 0.9385 (+/- 0.0112)\n",
      "  k=10: Precisión Promedio (CV en entrenamiento) = 0.9274 (+/- 0.0358)\n",
      "\n",
      "Evaluando modelo: Regresión Logística\n",
      "  k=5: Precisión Promedio (CV en entrenamiento) = 0.9473 (+/- 0.0146)\n",
      "  k=10: Precisión Promedio (CV en entrenamiento) = 0.9516 (+/- 0.0236)\n",
      "\n",
      "Evaluando modelo: k-NN (con escalado)\n",
      "  k=5: Precisión Promedio (CV en entrenamiento) = 0.9604 (+/- 0.0179)\n",
      "  k=10: Precisión Promedio (CV en entrenamiento) = 0.9647 (+/- 0.0205)\n",
      "\n",
      "Validación cruzada completada.\n",
      "\n",
      "--- Resumen de Precisión Promedio (Validación Cruzada en Set de Entrenamiento) ---\n",
      "      Árbol de Decisión  Regresión Logística  k-NN (con escalado)\n",
      "k=5            0.938462             0.947253             0.960440\n",
      "k=10           0.927440             0.951643             0.964734\n",
      "\n",
      "--- Conclusiones ---\n",
      "1. Mejor Modelo (según CV en entrenamiento):\n",
      "   - Con k=5: k-NN (con escalado) (Precisión CV: 0.9604)\n",
      "   - Con k=10: k-NN (con escalado) (Precisión CV: 0.9647)\n",
      "   (Estos resultados indican qué modelo parece generalizar mejor dentro del conjunto de entrenamiento).\n",
      "\n",
      "2. Impacto del valor de k (en CV sobre entrenamiento):\n",
      "   - Árbol de Decisión: La precisión CV empeoró al pasar de k=5 (0.9385) a k=10 (0.9274). Diferencia: -0.0110\n",
      "   - Regresión Logística: La precisión CV mejoró al pasar de k=5 (0.9473) a k=10 (0.9516). Diferencia: +0.0044\n",
      "   - k-NN (con escalado): La precisión CV mejoró al pasar de k=5 (0.9604) a k=10 (0.9647). Diferencia: +0.0043\n",
      "\n",
      "3. Consideraciones Adicionales:\n",
      "   - Estabilidad vs. Costo (Evaluación CV): Usar k=10 en la validación cruzada generalmente da una estimación más estable del rendimiento \n",
      "esperado, pero tarda más en calcular.\n",
      "   - Selección vs. Evaluación Final: La validación cruzada en el conjunto de entrenamiento ayuda a seleccionar el mejor enfoque. \n",
      "El conjunto de prueba (`X_test`, `y_test`) se reserva para la evaluación final.\n",
      "   - Interpretación: Los Árboles de Decisión pueden ser más interpretables, pero aquí la Regresión Logística y k-NN (con escalado) \n",
      "muestran mejor rendimiento promedio en CV.\n",
      "   - Sensibilidad a k: Observamos cómo varía la precisión promedio al cambiar k. Menor variación podría indicar mayor estabilidad.\n",
      "   - Próximos Pasos: Elegir el mejor modelo, reentrenarlo con todo `X_train`, `y_train` y evaluar su rendimiento definitivo usando \n",
      "`X_test`, `y_test`.\n"
     ]
    }
   ],
   "source": [
    "#1. Importar Librerías Necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# 2. Cargar y Preparar el Dataset\n",
    "# Cargamos el dataset directamente\n",
    "df = pd.read_csv('data.csv')\n",
    "print(\"Dataset cargado correctamente.\")\n",
    "\n",
    "# Eliminar columnas innecesarias si existen\n",
    "if 'id' in df.columns:\n",
    "    df = df.drop('id', axis=1)\n",
    "if 'Unnamed: 32' in df.columns:\n",
    "    df = df.drop('Unnamed: 32', axis=1)\n",
    "\n",
    "# Separar características (X) y variable objetivo (y)\n",
    "if 'diagnosis' not in df.columns:\n",
    "    print(\"Error: La columna 'diagnosis' no se encontró en el dataset.\")\n",
    "    exit()\n",
    "\n",
    "X = df.drop('diagnosis', axis=1)\n",
    "y = df['diagnosis']\n",
    "\n",
    "# Codificar la variable objetivo 'diagnosis' (Maligno=1, Benigno=0)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(\"Preparación de datos completada.\")\n",
    "\n",
    "# 3. Dividir el Dataset en Entrenamiento y Prueba\n",
    "# Dividimos los datos: 80% para entrenamiento, 20% para prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Usando .format() en lugar de f-strings\n",
    "print(\"\\nDataset dividido en:\")\n",
    "print(\"  - Conjunto de Entrenamiento: {} muestras\".format(X_train.shape[0]))\n",
    "print(\"  - Conjunto de Prueba: {} muestras\".format(X_test.shape[0]))\n",
    "\n",
    "# 4. Definir Modelos y Valores de k\n",
    "# Creamos los modelos que vamos a evaluar\n",
    "pipeline_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "models = {\n",
    "    'Árbol de Decisión': DecisionTreeClassifier(random_state=42),\n",
    "    'Regresión Logística': LogisticRegression(max_iter=10000, random_state=42),\n",
    "    'k-NN (con escalado)': pipeline_knn\n",
    "}\n",
    "\n",
    "# Definimos los valores de k para la validación cruzada\n",
    "k_values = [5, 10]\n",
    "\n",
    "# Diccionario para almacenar los resultados\n",
    "results_cv_train = {}\n",
    "\n",
    "print(\"\\nIniciando validación cruzada sobre el conjunto de entrenamiento...\")\n",
    "\n",
    "# 5. Aplicar Validación Cruzada K-Fold (sobre el Conjunto de Entrenamiento)\n",
    "# Iteramos sobre cada modelo\n",
    "for model_name, model in models.items():\n",
    "    # Usando .format()\n",
    "    print(\"\\nEvaluando modelo: {}\".format(model_name))\n",
    "    results_cv_train[model_name] = {}\n",
    "    # Iteramos sobre cada valor de k\n",
    "    for k in k_values:\n",
    "        # Configuramos la validación cruzada K-Fold\n",
    "        kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "        # Realizamos la validación cruzada USANDO SOLO LOS DATOS DE ENTRENAMIENTO\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "        # Calculamos la precisión promedio y la desviación estándar\n",
    "        mean_accuracy = np.mean(cv_scores)\n",
    "        std_accuracy = np.std(cv_scores)\n",
    "\n",
    "        # Guardamos los resultados usando .format() para la clave del diccionario\n",
    "        results_cv_train[model_name]['k={}'.format(k)] = mean_accuracy\n",
    "\n",
    "        # Usando .format() para imprimir resultados, incluyendo formato de decimales\n",
    "        print(\"  k={}: Precisión Promedio (CV en entrenamiento) = {:.4f} (+/- {:.4f})\".format(k, mean_accuracy, std_accuracy))\n",
    "\n",
    "print(\"\\nValidación cruzada completada.\")\n",
    "\n",
    "# 6. Comparar Resultados (Basados en CV del set de entrenamiento) y Conclusiones\n",
    "\n",
    "print(\"\\n--- Resumen de Precisión Promedio (Validación Cruzada en Set de Entrenamiento) ---\")\n",
    "results_df = pd.DataFrame(results_cv_train)\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\n--- Conclusiones ---\")\n",
    "\n",
    "# Comparación general entre modelos basada en CV sobre datos de entrenamiento\n",
    "best_model_k5 = results_df.loc['k=5'].idxmax()\n",
    "best_acc_k5 = results_df.loc['k=5'].max()\n",
    "best_model_k10 = results_df.loc['k=10'].idxmax()\n",
    "best_acc_k10 = results_df.loc['k=10'].max()\n",
    "\n",
    "# Usando .format()\n",
    "print(\"1. Mejor Modelo (según CV en entrenamiento):\")\n",
    "print(\"   - Con k=5: {} (Precisión CV: {:.4f})\".format(best_model_k5, best_acc_k5))\n",
    "print(\"   - Con k=10: {} (Precisión CV: {:.4f})\".format(best_model_k10, best_acc_k10))\n",
    "print(\"   (Estos resultados indican qué modelo parece generalizar mejor dentro del conjunto de entrenamiento).\")\n",
    "\n",
    "# Comparación del impacto de k para cada modelo\n",
    "# Usando .format()\n",
    "print(\"\\n2. Impacto del valor de k (en CV sobre entrenamiento):\")\n",
    "for model_name in results_cv_train.keys():\n",
    "    acc_k5 = results_cv_train[model_name]['k=5']\n",
    "    acc_k10 = results_cv_train[model_name]['k=10']\n",
    "    diff = acc_k10 - acc_k5\n",
    "    change = \"mejoró\" if diff > 0 else \"empeoró\" if diff < 0 else \"se mantuvo igual\"\n",
    "    # Usando .format() con múltiples argumentos y especificadores de formato\n",
    "    print(\"   - {}: La precisión CV {} al pasar de k=5 ({:.4f}) a k=10 ({:.4f}). Diferencia: {:+.4f}\".format(model_name, change, acc_k5, acc_k10, diff))\n",
    "\n",
    "print(\"\\n3. Consideraciones Adicionales:\")\n",
    "print(\"\"\"   - Estabilidad vs. Costo (Evaluación CV): Usar k=10 en la validación cruzada generalmente da una estimación más estable del rendimiento \n",
    "esperado, pero tarda más en calcular.\"\"\")\n",
    "print(\"\"\"   - Selección vs. Evaluación Final: La validación cruzada en el conjunto de entrenamiento ayuda a seleccionar el mejor enfoque. \n",
    "El conjunto de prueba (`X_test`, `y_test`) se reserva para la evaluación final.\"\"\")\n",
    "print(\"\"\"   - Interpretación: Los Árboles de Decisión pueden ser más interpretables, pero aquí la Regresión Logística y k-NN (con escalado) \n",
    "muestran mejor rendimiento promedio en CV.\"\"\")\n",
    "print(\"   - Sensibilidad a k: Observamos cómo varía la precisión promedio al cambiar k. Menor variación podría indicar mayor estabilidad.\")\n",
    "print(\"\"\"   - Próximos Pasos: Elegir el mejor modelo, reentrenarlo con todo `X_train`, `y_train` y evaluar su rendimiento definitivo usando \n",
    "`X_test`, `y_test`.\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
